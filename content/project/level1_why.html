
<div>
   
  With the <span onclick="expandCat(&quot;l2_progress&quot;)" class="expandable">technological progress and automation of human labor</span><span></span>
  <div id="l2_progress" class="contentLevel2 ">
    <div>
       
      In the eighteenth century, a series of inventions transformed the manufacture of cotton in England and gave rise to a new mode of production – the factory system, marking the early signs of the <span onclick="expandCat(&quot;l3_revolution&quot;)" class="expandable">First Industrial Revolution</span><span>.</span>
      <div id="l3_revolution" class="contentLevel3 ">
        <div> </div>During these years, other branches of industry effected comparable advances, and all these together, mutually reinforcing one another, made possible further gains on an ever-widening front. The abundance and variety of these innovations almost defy compilation, but they may be subsumed under three principles: the substitution of machines – rapid, regular, precise, tireless – for human skill and effort; the substitution of inanimate for animate sources of power, in particular, the introduction of engines for converting heat into work, thereby opening to man a new and almost unlimited supply of energy; the use of new and far more abundant raw materials, in particular, the substitution of mineral for vegetable or animal substances. These improvements constitute the Industrial Revolution. <a href="http://www.historyguide.org/intellect/lecture17a.html" target="_blank" data-toggle="tooltip" data-placement="top" title="The History Guide"><i aria-hidden="true" class="fa fa-external-link externalLink"></i></a>
        <div class="closeButton"><i aria-hidden="true" onclick="expandCat(&quot;l3_revolution&quot;)" class="fa fa-times externalLink"></i></div>
      </div>
    </div>
    <div>
       
      From the very moment machines could handle any sort of repetitive task, people have worried about human labor being substituted by machines. For example, as early as 1772 the British writer Thomas Mortimer criticised heavily the use of sawmills in manufacturing of cotton, which “if introduced into our dockyards would exclude the labor of thousands of useful workmen.” <a href="https://books.google.ru/books?id=3sJgAAAAcAAJ&amp;pg=PA72&amp;lpg=PA72&amp;dq=thomas+mortimer+%22exclude+the+labour+of+thousands%22&amp;source=bl&amp;ots=FnZP4FpHWt&amp;sig=sj9TpGQB0ABwZrE_lbmYxPdjoQo&amp;hl=en&amp;sa=X&amp;redir_esc=y#v=onepage&amp;q=thomas%20mortimer%20%22exclude%20the%20labour%20of%20thousands%22&amp;f=false" target="_blank" data-toggle="tooltip" data-placement="top"><i aria-hidden="true" class="fa fa-external-link externalLink"></i></a>
    </div>
    <div>
       
      The fear of devaluation of human labor soon <span onclick="expandCat(&quot;marx&quot;)" class="expandable">became the concern of philosophers and theorists such as Karl Marx</span><span>,</span>
      <div id="marx" class="contentLevel3 ">
        <div>The factory lord has become a penal legislator within his own establishment, inflicting fines at will, frequently for his own aggrandisement. The feudal baron in his dealings with his serfs was bound by traditions and subject to certain definite rules; the factory lord is subject to no controlling agency of any kind. <a href="https://www.marxists.org/archive/marx/iwma/documents/1868/machinery-speech.htm" target="_blank" data-toggle="tooltip" data-placement="top" title="Marx in an address to the International Workingman’s Association in 1868"><i aria-hidden="true" class="fa fa-external-link externalLink"></i></a>
        </div>
        <div class="closeButton"><i aria-hidden="true" onclick="expandCat(&quot;marx&quot;)" class="fa fa-times externalLink"></i></div>
      </div>and it wasn’t long before it became a domain of writers working in the realm of speculation. Question was raised - “if machines can duplicate and even replace human muscle, could they do the same with the human brain?”, giving rise to the genre of science fiction. 
    </div>
    <div>
       
      Even though multiple technological advancements of <span onclick="expandCat(&quot;second&quot;)" class="expandable">Second</span><span></span>
      <div id="second" class="contentLevel3 "> 
        <div>The Second Industrial Revolution was another great leap forward in technology and society. New innovations in steel production, petroleum and electricity led to the introduction of public automobiles and airplanes.<a href="https://en.wikipedia.org/wiki/Second_Industrial_Revolution" target="_blank" data-toggle="tooltip" data-placement="top"><i aria-hidden="true" class="fa fa-external-link externalLink"></i></a>
        </div>
        <div class="closeButton"><i aria-hidden="true" onclick="expandCat(&quot;second&quot;)" class="fa fa-times externalLink"></i></div>
      </div>and <span onclick="expandCat(&quot;third&quot;)" class="expandable">Third Industrial Revolutions</span><span></span>
      <div id="third" class="contentLevel3 "> 
        <div>The Third Industrial Revolution, also known as Digital Revolution began in 1970 with wide adoption of digital computers and used electronics and information technology to automate production. Central to this revolution is the mass production and widespread use of digital logic circuits, and its derived technologies, including the computer, digital cellular phone, and the Internet.<a href="https://en.wikipedia.org/wiki/Digital_Revolution" target="_blank" data-toggle="tooltip" data-placement="top"><i aria-hidden="true" class="fa fa-external-link externalLink"></i></a>
        </div>
        <div class="closeButton"><i aria-hidden="true" onclick="expandCat(&quot;third&quot;)" class="fa fa-times externalLink"></i></div>
      </div>often appeared to take jobs away, in the long run they led to the creation of new jobs, and have never created a serious obstacle for those who wanted to work, and all was well. The invention of, say, the internal-combustion engine put buggy-whip makers and carriage assemblers out of business, but it created many more jobs in the manufacturing and maintenance of automobiles, similarly as carriage drivers were simply replaced by truck drivers. In other words, as society progressed, the nature of labor has simply changed from manual to mechanized to computer automated labor. So how is it different this time?
    </div>
    <div> Currently, artificial intelligence algorithms have been developed such that machines can exceed human intelligence for completing specific tasks efficiently – ranging from automatic language translation to self driven cars <a href="http://fortune.com/2016/02/10/google-self-driving-cars-artificial-intelligence/" target="_blank" data-toggle="tooltip" data-placement="top"><i aria-hidden="true" class="fa fa-external-link externalLink"></i></a>. Considering the pace <a href="http://28oa9i1t08037ue3m1l0i861.wpengine.netdna-cdn.com/wp-content/uploads/2015/01/PPTExponentialGrowthof_Computing-1.jpg" target="_blank" data-toggle="tooltip" data-placement="top"><i aria-hidden="true" class="fa fa-external-link externalLink"></i></a><a href="http://www.amazon.com/gp/product/0143037889/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0143037889&amp;linkCode=as2&amp;tag=wabuwh00-20&amp;linkId=54Q62R5PYJBEENTP" target="_blank" data-toggle="tooltip" data-placement="top"><i aria-hidden="true" class="fa fa-external-link externalLink"></i></a>and the trajectory of development of the artificial intelligence framework<a href="http://www.wired.com/2010/08/reverse-engineering-brain-kurzweil/" target="_blank" data-toggle="tooltip" data-placement="top"><i aria-hidden="true" class="fa fa-external-link externalLink"></i></a>, in the future, technologies will be capable of doing everything that human beings are employed for presently, while utilising vastly less human labour. 
    </div>
    <div class="closeButton"><i aria-hidden="true" onclick="expandCat(&quot;l2_progress&quot;)" class="fa fa-times externalLink"></i></div>
  </div>we are transitioning to the <span onclick="expandCat(&quot;l2_info_economy&quot;)" class="expandable">information economy</span><span>,</span>
  <div id="l2_info_economy" class="contentLevel2 ">
    <div>
       
      We have entered an economy in which knowledge and information is the primary raw material and source of value. It is being enabled by convergence of communication and data processing technologies into information technology (IT). Information economy is characterised by pervasive influence of IT on economic activity and every aspect of cultural, political, and social life which is based on the production and distribution of information. In such economy the most workers are information workers and most products are information products.  In a longer run that naturally divides society into new classes: those who are information-rich and those who are information-poor.<a href="https://en.wikipedia.org/wiki/Information_economy" target="_blank" data-toggle="tooltip" data-placement="top"><i aria-hidden="true" class="fa fa-external-link externalLink"></i></a>
    </div>
    <div class="closeButton"><i aria-hidden="true" onclick="expandCat(&quot;l2_info_economy&quot;)" class="fa fa-times externalLink"></i></div>
  </div>where <span onclick="expandCat(&quot;l2_info_new_work&quot;)" class="expandable">production of information becomes the new nature of work</span><span>.</span>
  <div id="l2_info_new_work" class="contentLevel2 ">
    <div>
       
      As we’ve seen throughout the history, technological progress and automation of human labor simply changed the nature of work and oftentimes created more new jobs. However, since the future is a place of accelerating changes, it would be unwise trying to predict it by only looking at the past. In other words, if new jobs simply appeared in the past, it doesn’t mean they always will, at least in traditional sense of the notion.
    </div>
    <div>
       
      World Economic Forum report on Future of Jobs <a href="http://www3.weforum.org/docs/WEF_Future_of_Jobs.pdf" target="_blank" data-toggle="tooltip" data-placement="top"><i aria-hidden="true" class="fa fa-external-link externalLink"></i></a>stimates the creation of 2 million new jobs alongside the elimination of 7 million by 2020, which means a net loss of 5 million jobs. Another frequently cited study by Oxford Martin School<a href="https://www.technologyreview.com/s/519241/report-suggests-nearly-half-of-us-jobs-are-vulnerable-to-computerization/" target="_blank" data-toggle="tooltip" data-placement="top"><i aria-hidden="true" class="fa fa-external-link externalLink"></i></a>estimates the automation of about half of the jobs existing today by 2033. Lastly, now even the White House in its report to the Congress <a href="https://www.whitehouse.gov/sites/default/files/docs/ERP_2016_Book_Complete%20JA.pdf" target="_blank" data-toggle="tooltip" data-placement="top"><i aria-hidden="true" class="fa fa-external-link externalLink"></i></a>, estimates 83 percent chances of eventually losing job to a machine for a worker making $20 an hour or less. Even highly paid workers earning as much as $40 an hour face chances of 31 percent. This all is being achieved thanks to machine learning, or artificial intelligence, that has an impact on any industry in any country: from automatic language translation to self driving vehicles to optimization of processes in production, marketing and advertising. In other words, machine learning has the capability of drastically impacting all economies — by eliminating millions of jobs within a short span of time.
    </div>
    <div>When it comes to information, we are creating increasingly more of it every day. Thanks to digitization of our daily activities and further proliferation of Internet, in 2015 alone we are liking 4.2 million things on Facebook, uploading 300 hours of videos on YouTube and creating 350,000 tweets every single minute <a href="https://www.domo.com/blog/2015/08/data-never-sleeps-3-0/" target="_blank" data-toggle="tooltip" data-placement="top"><i aria-hidden="true" class="fa fa-external-link externalLink"></i></a>, the amount of data we are creating is doubling every 1.5 years <a href="http://www.datamation.com/applications/big-data-analytics-overview.html" target="_blank" data-toggle="tooltip" data-placement="top"><i aria-hidden="true" class="fa fa-external-link externalLink"></i></a>. According to 2013 report by SINTEF, 90% of all information in the world has been created in the prior two years <a href="https://www.sciencedaily.com/releases/2013/05/130522085217.htm" target="_blank" data-toggle="tooltip" data-placement="top"><i aria-hidden="true" class="fa fa-external-link externalLink"></i></a>. Everything we do is generating data like never before, and lots of data is exactly what machines need in order to learn.
    </div>
    <div>Imagine programming a computer to recognize a table. You would need to write a lot of instructions and complex algorithms, and still you would have a program that would never do it as well as a human being. However, if instead of providing computer complex algorithms, you upload thousands of images of things that are similar to tables — it would do a much better job. This is called reinforcement learning, and is very similar to the process human beings use to learn. When we learn to recognize a table, the label “table” gets connected to every table we see, such that certain neural pathways are reinforced and others aren’t. For “table” to fire in our brains, what we see has to be close enough to our previous table encounters. This principle is clearly visible in the <span onclick="expandCat(&quot;languageHistory&quot;)" class="expandable">history of automatic language translation</span><span>.</span>
      <div id="languageHistory" class="contentLevel3 ">
        <div>With the first developments of machine learning, or Artificial Intelligence, people have tried to create an algorithm that would translate between languages. Initially this sounded like a comparatively simple task: in 1960s Marvin Minsky, pioneer in the field of Artificial Intelligence, then professor at MIT AI Lab, tasked his students with developing such an algorithm as part of a summer project. This has proved to be unsuccessful, however. Creating an algorithm that would account for all the nuances and subtleties of human speech proved to be too difficult. It took AI enthusiasts 30 more years of trials before people at IBM found the working formula. The secret was simple: to use multiple examples of translations by real people as a material for teaching the machine. Today, all major automatic language translators work this way. Data with samples of millions of real translations is gathered across the internet, and is being fed to algorithms to perform translations online. This principle allows computer translators to remain up to date even despite natural evolution of human language and appearance of slang. </div>
        <div class="closeButton"><i aria-hidden="true" onclick="expandCat(&quot;languageHistory&quot;)" class="fa fa-times externalLink"></i></div>
      </div>
    </div>
    <div>
       
      Currently, artificial intelligence algorithms are developed in that way in which machines can exceed human intelligence for completing specific tasks efficiently – ranging from automatic language translation to self driven cars<a href="http://fortune.com/2016/02/10/google-self-driving-cars-artificial-intelligence/" target="_blank" data-toggle="tooltip" data-placement="top"><i aria-hidden="true" class="fa fa-external-link externalLink"></i></a>. Considering the pace<a href="http://28oa9i1t08037ue3m1l0i861.wpengine.netdna-cdn.com/wp-content/uploads/2015/01/PPTExponentialGrowthof_Computing-1.jpg" target="_blank" data-toggle="tooltip" data-placement="top"><i aria-hidden="true" class="fa fa-external-link externalLink"></i></a><a href="http://www.amazon.com/gp/product/0143037889/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0143037889&amp;linkCode=as2&amp;tag=wabuwh00-20&amp;linkId=54Q62R5PYJBEENTP" target="_blank" data-toggle="tooltip" data-placement="top"><i aria-hidden="true" class="fa fa-external-link externalLink"></i></a>and the trajectory of development of the artificial intelligence framework<a href="http://www.wired.com/2010/08/reverse-engineering-brain-kurzweil/" target="_blank" data-toggle="tooltip" data-placement="top"><i aria-hidden="true" class="fa fa-external-link externalLink"></i></a>, in the future, technologies will be capable of doing everything that human beings are employed for presently, while utilising vastly less human labour. In other words, more and more jobs in the future will be automated by algorithms and machines, but in order to function, those machines need information that is still produced by people. 
    </div>
    <div class="closeButton"><i aria-hidden="true" onclick="expandCat(&quot;l2_info_new_work&quot;)" class="fa fa-times externalLink"></i></div>
  </div>
</div>
<div>
   
  Failing to recognize that — and claim ownership of our own data — leads to <span onclick="expandCat(&quot;l2_monopoly&quot;)" class="expandable">monopolization of information markets</span><span>,</span>
  <div id="l2_monopoly" class="contentLevel2 ">
    <div>You might have noticed it already. There is a strange logic at the heart of the modern tech industry. The goal of many new tech startups is not to produce products or services for which consumers are willing to pay. Instead, the goal is to create a digital platform or hub that will capture information from as many users as possible — to grab as many ‘eyeballs’ as you can. <span onclick="expandCat(&quot;whatsapp&quot;)" class="expandable">The story of WhatsApp</span><span>,</span>
      <div id="whatsapp" class="contentLevel3 ">
        <div>
           
          In 2014, then a 4-years-old WhatsApp, an application that provides users a simple interface enabling people to stay in touch with each other, was sold to Facebook for astonishing $22 billions. At the time of the purchase there were 55 employees at WhatsApp, which served 400 millions of people. That makes this acquisition the largest transaction done by any two companies backed by venture capitalists.<a href="https://en.wikipedia.org/wiki/WhatsApp" target="_blank" data-toggle="tooltip" data-placement="top"><i aria-hidden="true" class="fa fa-external-link externalLink"></i></a>
        </div>
        <div class="closeButton"><i aria-hidden="true" onclick="expandCat(&quot;whatsapp&quot;)" class="fa fa-times externalLink"></i></div>
      </div>for instance, is just one of numerous examples. 
    </div>
    <div>Shoshana Zuboff, the famous Harvard business theorist, calls this phenomenon surveillance capitalism <a href="http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2594754" target="_blank" data-toggle="tooltip" data-placement="top"><i aria-hidden="true" class="fa fa-external-link externalLink"></i></a>. She believes that it has its own logic, distinct from other forms of capitalism, that needs to be carefully and critically assessed. She is not alone in raising concerns over the ever-growing influence tech companies are gaining due to the unrestricted and exclusive access to the information. So how does it really work?
    </div>
    <div>
       
      It starts with providing, usually free, services for people and collecting as much information as possible in the process of usage. There seems to be an insatiable appetite for capture of ever-increasing volumes of information from ever-expanding array of sources. Since users have little awareness and control about information being collected, it is becoming relatively easy and cheap to do so, and tech companies rarely discriminate against which information is valuable and which is not. Everything goes: our social preferences, buying history, likes, activity logs and many more. Tons of information is being pumped into the ever-growing servers every second. 
    </div>
    <div>
       
      Once information is captured, it can then be analyzed and monetized as it allows to understand people’s behaviors. This feature makes data the main ingredient in <span onclick="expandCat(&quot;l3_adRecipe&quot;)" class="expandable">the recipe for perfect advertising</span><span>.</span>
      <div id="l3_adRecipe" class="contentLevel3 ">
        <div>Today, advertising constitutes 20-60% of product price. That means the more effective advertising is, the cheaper the product becomes, which makes it more attractive against the market competition. In other words, in order to remain competitive, companies are striving to increase effectiveness of advertising by showing targeted messages only to people who are already interested in buying certain products, and therefore eliminate wastage associated with traditional advertising approach — where large and non-specific groups of people are exposed to an ad content. This approach — called targeted advertisement — is enabled by large amounts of data collected from people. The data allows to analyze past behavior of users and predict future behaviors and needs. </div>
        <div><img src="img/18_ad_recipe.png"/></div>
        <div class="closeButton"><i aria-hidden="true" onclick="expandCat(&quot;l3_adRecipe&quot;)" class="fa fa-times externalLink"></i></div>
      </div>
    </div>
    <div>The old logic where advertisers purchase space or time in media with hope to get user’s attention is quickly becoming obsolete. Instead of addressing rather general audience thought key media channels, they can now skip media altogether, tailor message to a specific person, and locate them anywhere online (and increasingly in physical space) due to ubiquitous surveillance. This results in a much more efficient advertising. And since marketing and advertising are naturally moving towards greater efficiency, companies that have access to the largest amounts of data naturally become the most powerful players in the advertising market (Google and Facebook have monopoly on search queries and social graphs respectively). The above mentioned duo, combined, receives over 70% of all the dollars spent on online advertising in the US.</div>
    <div>On the user’s side, the collected information allows to personalize and improve free services provided, thus attracting even more loyal users, allowing to collect even more precise information and make the system more attractive to marketers and advertisers. This creates a self-reinforcing loop, which becomes hard to escape. As omnipresent technologies become the new social norm, people rarely are willing to make a sacrifice for privacy or ethical concerns. It makes for an interesting phenomenon in which tech companies are becoming the wealthiest charities out there: users are giving away the very resource that makes them so powerful for free.</div>
    <div><img src="img/3_monopoly.png"/></div>
    <div>As a result, Google and Facebook quickly became monopolies in their respective fields, representing about 70% of online advertising market share. Companies that had not existed before 2003, now became unquestionable part of any marketing strategy. The recipe is working so well, however, that surveillance capitalism companies are entering the real world in order to collect more information about their users. While collecting data online allows for serving targeted ads, information collected from the connected objects and wearables allows to understand, anticipate human behavior in real time and <span onclick="expandCat(&quot;profit&quot;)" class="expandable">then shape it for profit</span><span>.</span>
      <div id="profit" class="contentLevel3 ">
        <div>
           
          Let’s use a couple of real life examples of technologies that are already in place or are under development. Auto insurance industry, for example, is one of those that has been notoriously exploitative toward customers and has had obvious reasons to be anxious about the implications of self-driving cars for its business model. As Shoshanna Zuboff famously put it in her article: ”Now, that data about where we are, where we’re going, how we’re feeling, what we’re saying, the details of our driving, and the conditions of our vehicle are turning into beacons of revenue that illuminate a new commercial prospect. According to the industry literature, these data can be used for dynamic real-time driver behavior modification triggering punishments (real-time rate hikes, financial penalties, curfews, engine lock-downs) or rewards (rate discounts, coupons, gold stars to redeem for future benefits).”
        </div>
        <div>This is just one example, in one corner, of one industry, and the examples are multiplying day by day. Among the many interviews Shoshanna have conducted over the past three years, the Chief Data Scientist of a much-admired Silicon Valley startup that develops products to improve students’ learning told, “The goal of everything we do is to change people’s actual behavior at scale. When people use our app, we can capture their behaviors, identify good and bad behaviors, and develop ways to reward the good and punish the bad. We can test how actionable our cues are for them and how profitable for us”.</div>
        <div>The whole paradigm of a functional, effective, affordable product as a basis for economic exchange is becoming thing of the past. The sports apparel company Under Armour is reinventing its products as wearable devices. The CEO wants to be like Google. He says, "If it all sounds eerily like those ads that, because of your browsing history, follow you around the Internet, that's exactly the point – except Under Armour is tracking real behavior and the data is more specific… making people better athletes makes them need more of our gear.”  The examples of this new logic are countless, from smart vodka bottles <a href="http://phys.org/news/2015-05-ready-liquor-bottles-smart.html" target="_blank" data-toggle="tooltip" data-placement="top"><i aria-hidden="true" class="fa fa-external-link externalLink"></i></a>to Internet-enabled rectal thermometers <a href="https://motherboard.vice.com/read/this-rectal-thermometer-is-the-logical-conclusion-of-the-internet-of-things" target="_blank" data-toggle="tooltip" data-placement="top"><i aria-hidden="true" class="fa fa-external-link externalLink"></i></a>and quite literally everything in between. A Goldman Sachs report<a href="https://hbr.org/2014/10/the-sectors-where-the-internet-of-things-really-matters/" target="_blank" data-toggle="tooltip" data-placement="top"><i aria-hidden="true" class="fa fa-external-link externalLink"></i></a>calls it a “gold rush,” a race to “vast amounts of data.”
        </div>
        <div>If we take a step back and think, almost every aspect of our lives is now shaped by technology. The places we go for a dinner after checking reviews online, the algorithmically selected music to fit our taste, the places we stay at during our travels, the cars we drive, the routes we drive through, people we date – the list goes on and on. The game is no longer about sending you a mail order catalogue or even targeted online advertising. The game is selling access to the real-time flow of your daily life – your reality – in order to directly influence and modify your behavior for profit. This is the gateway to a new universe of monetization opportunities: restaurants who want to be your destination. Service vendors who want to fix your bike wheels. Shops who will lure you by targeted offers. Essentially everyone who wants a piece of your behavior for profit. Small wonder, then, that Google recently announced<a href="http://www.wsj.com/articles/google-maps-suggests-destination-1452730965" target="_blank" data-toggle="tooltip" data-placement="top"><i aria-hidden="true" class="fa fa-external-link externalLink"></i></a>that its maps will not only provide the route you search but will also suggest a destination.
        </div>
        <div class="closeButton"><i aria-hidden="true" onclick="expandCat(&quot;profit&quot;)" class="fa fa-times externalLink"></i></div>
      </div>This phenomenon called “reality mining” is at heart of most surveillance capitalism projects and is the basis for the perfect form of advertising — where people’s behavior is simply subconsciously shaped to profit companies in question, without having to advertise anything.
    </div>
    <div class="closeButton"><i aria-hidden="true" onclick="expandCat(&quot;l2_monopoly&quot;)" class="fa fa-times externalLink"></i></div>
  </div>
</div>
<div>
   
  which, when coupled with <span onclick="expandCat(&quot;l2_further_development&quot;)" class="expandable">further development of technology</span><span>,</span>
  <div id="l2_further_development" class="contentLevel2 ">
    <div>In parallel with the development of physical networks and the current tendency to connect everything and everybody to each other, there is an extremely fast development of technologies that connect us to the network. As the <span onclick="expandCat(&quot;historyOfDev&quot;)" class="expandable">history of development of human-to-computer interfaces</span><span></span>
      <div id="historyOfDev" class="contentLevel3 ">
        <div>Let’s try to build a quick timeline to better understand the direction of this evolution. From the simplest binary data writing the technology moved on to microchips before it evolved into batch interfaces – non-interactive interfaces, where the user specifies all the details of the batch job in advance to batch processing, and receives the output when all the processing is done. The next great improvement was the command line interfaces (CLI), which is one of the most efficient tool even today. Commands are sent to the program in the form of successive lines of text.</div>
        <div><img src="img/4_cli.png"/></div>
        <div>The next step of User Interface evolution became graphical user interface (GUI), which was a much more convenient way to interact with computers. It provided a wide range of graphical elements, such as windows, menus, radio buttons, and checkboxes. In addition to keyboard, it allowed to use mouse as a controller. This is was an already great step forward, which opened a wide range of usage of personal computers.</div>
        <div>In the 90s, with the invention and popularisation of the Internet, GUI became the main medium for communications in the web. Web-based user interfaces formed new group of interfaces that could accept input and provide output by generating web pages transmitted via the Internet and shown in a web browser.</div>
        <div>With further development of screens and computing power of personal devices the new type of input gained popularity - touch screens. From the user’s perspective they almost removed the interface part as a middleman between human and digital objects. Now we touch and manipulate digital abstractions almost as if they were real objects.</div>
        <div>Gestures, voice, natural-language processing - modern devices can track and use as an input almost every way of communication available to human. This is why the next evolution of interfaces is expected to be even more contextual and less intrusive, virtually blending with the surrounding environment.</div>
        <div class="closeButton"><i aria-hidden="true" onclick="expandCat(&quot;historyOfDev&quot;)" class="fa fa-times externalLink"></i></div>
      </div>shows, we are steadily moving to more immersive and natural interfaces. From people having to 'speak computer language' in early days of digital computing, we are now transitioning towards new paradigm, where computer interfaces are designed in the way most natural for human brain to comprehend. Naturally blending with the three dimensional environment around us, as opposed to being confined by a screen. This transition is being enabled by rapid development of series of technologies such as ubiquitous, distributed sensors, smart, connected materials, holographic projections as well as Virtual Reality (VR) and Augmented Reality (AR). Expected to become mainstream and disrupt mobile by 2020<a href="http://techcrunch.com/2015/04/06/augmented-and-virtual-reality-to-hit-150-billion-by-2020/" target="_blank" data-toggle="tooltip" data-placement="top"><i aria-hidden="true" class="fa fa-external-link externalLink"></i></a>, it has already attracted major investments from every leading tech company, and has been named the next major computing platform by people like Mark Zuckerberg<a href="http://www.infoworld.com/article/2610667/m-a/zuckerberg-sees-virtual-reality-as-next-major-computing-platform.html" target="_blank" data-toggle="tooltip" data-placement="top"><i aria-hidden="true" class="fa fa-external-link externalLink"></i></a>. 
    </div>
    <div>As we have seen, with every next step in the evolution, interfaces become more and more natural and non-intrusive. From bits to words to images and movies to immersive environments. In the context of generation and data capturing, however, there are two key points worth mentioning. First of all, with every leap in development of technology, the amount of information generated as byproduct of its activity increases exponentially. From point interaction and meta-data measured in bytes at the times of Command Line Interfaces to continuous flow of rich metadata captured while using devices, such as Microsoft HoloLense, for example, which is considered to be one of the pioneers of AR. Today, when all the communication flows are routinely tracked by digital infrastructure providers in order to serve you with personalized advertising, even simple digital traces - like search queries on the web - can sometimes say more about you than you know yourself<a href="http://www.forbes.com/sites/kashmirhill/2012/02/16/how-target-figured-out-a-teen-girl-was-pregnant-before-her-father-did/#2489d2b734c6" target="_blank" data-toggle="tooltip" data-placement="top"><i aria-hidden="true" class="fa fa-external-link externalLink"></i></a>. If your identity can now be identified by the mere trajectory of cursor movement<a href="http://miro.enev.us/docs/mouse_ID.pdf" target="_blank" data-toggle="tooltip" data-placement="top"><i aria-hidden="true" class="fa fa-external-link externalLink"></i></a>, what potential there is in the device that continuously traces your eye movement and movement throughout space? 
    </div>
    <div><img src="img/21_growth_of_data.png"/></div>
    <div>Secondly, and even more importantly, Augmented Reality devices – that add an additional digital layer to the perceptible world – hold (yet little explored) potential for influencing and modifying our behavior. By augmenting our reality with metadata, additional objects and context overlays, AR has almost the same level of immersiveness as the physical world. All the available tools for people who moderate our physical reality (architects, advertisers, city planners, interior designers) are also available for those who design this virtual overlay. That, in fact, provides almost the maximum level of efficiency in affecting our world perception and behavior.</div>
    <div class="closeButton"><i aria-hidden="true" onclick="expandCat(&quot;l2_further_development&quot;)" class="fa fa-times externalLink"></i></div>
  </div>results in: 
  <ol>
    <div class="liWrapper1">
      <div class="numberCircle1">1</div>
      <div class="liText1"><span onclick="expandCat(&quot;l2_limitations&quot;)" class="expandable">limitation of creativity and economic growth through the use of data;</span><span></span>
        <div id="l2_limitations" class="contentLevel2 ">
          <div>It’s pretty easy. If only a few companies owned the precious data and metadata (as we have established, these are the foundation of  the information economy), they would not only become the wealthiest and most powerful companies (e.g. Alphabet). Being the only ones able to access the raw material, they also become the only ones that can develop the possible usages of the data. One could compare it with a situation in which there are no public libraries, but all companies and institutions have their own secluded knowledge base – it would obviously limit the amount of people able to use the information and, thus, strongly hold the development back. Now we have a case in which few companies have accumulated the main bulk of information, so it is centralized and can be well analyzed. However, since the database is not open to everyone, it is only used for the purposes benefitting these companies. It makes it impossible for others to use the information in more creative ways and prevents a competitive market from emerging. Right now a handful of companies dictate what needs to be and what should be developed, how it is developed and who it benefits.</div>
          <div class="closeButton"><i aria-hidden="true" onclick="expandCat(&quot;l2_limitations&quot;)" class="fa fa-times externalLink"></i></div>
        </div>
      </div>
    </div>
    <div class="liWrapper1">
      <div class="numberCircle1">2</div>
      <div class="liText1"><span onclick="expandCat(&quot;l2_dangerous&quot;)" class="expandable">dangerous precedents in manipulation of behavior;</span><span></span>
        <div id="l2_dangerous" class="contentLevel2 ">
          <div>The access to a huge amount of data and metadata equals a tremendous power. The metadata tells about how users are behaving and interacting, and the more activity (social, work, experience, education, treatment) we move into the digital realm, the more meta-data is produced. </div>
          <div>One of the main characteristics of the <span onclick="expandCat(&quot;fourthRev&quot;)" class="expandable">Fourth Industrial Revolution is the creation</span><span></span>
            <div id="fourthRev" class="contentLevel3 ">
              <div>
                 
                Fourth Industrial Revolution is building on the Third, the digital revolution that has been occurring since the middle of the last century. It is characterized by a fusion of technologies that is blurring the lines between the physical, digital, and biological spheres. The speed of current breakthroughs has no historical precedent. When compared with previous industrial revolutions, the Fourth is evolving at an exponential rather than a linear pace. Moreover, it is disrupting almost every industry in every country. And the breadth and depth of these changes herald the transformation of entire systems of production, management, and governance. <a href="https://www.weforum.org/agenda/2016/01/the-fourth-industrial-revolution-what-it-means-and-how-to-respond/" target="_blank" data-toggle="tooltip" data-placement="top" title="World Economic Forum"><i aria-hidden="true" class="fa fa-external-link externalLink"></i></a>
              </div>
              <div class="closeButton"><i aria-hidden="true" onclick="expandCat(&quot;fourthRev&quot;)" class="fa fa-times externalLink"></i></div>
            </div>of virtual copies of the physical world in order to make decisions that are then applied back to the physical world. Our behavior is certainly not an exception. It is also analyzed to be later targeted. But it doesn’t stop there. The digital models of our behaviour can also tell what to do in order to manipulate and re-shape our behavior in the way that would be beneficial for those who create the model. Hence the power of vast amount of metadata. 
          </div>
          <div class="closeButton"><i aria-hidden="true" onclick="expandCat(&quot;l2_dangerous&quot;)" class="fa fa-times externalLink"></i></div>
        </div>
      </div>
    </div>
    <div class="liWrapper1">
      <div class="numberCircle1">3</div>
      <div class="liText1"><span onclick="expandCat(&quot;l2_dunsustainable&quot;)" class="expandable">unsustainable wealth distribution that leads to erosion of the middle class and market society</span><span></span>
        <div id="l2_dunsustainable" class="contentLevel2 lastElement">
          <div>
             
            As we have established, within this increasingly automated world, there is an emerging logic of value production. Information is first being generated by people and is eventually collected and processed by machines where value is being generated (information still playing key role in supporting functionality of artificial intelligence or development of new products, for example). As this trend strengthens, we have more and more value being generated and accumulated at the later stages of production chain, leaving real producers with less opportunities to profit from their contribution. 
          </div>
          <div>In other words, if this intelligence is provided by the people for free, the raw material required to develop and run this artificial intelligent system won’t be part of the economy anymore. And, the more the information or the information providers are treated as a consequence and not the core value, the more the economy will shrink as this automated system continues to advance; resulting in a much larger macroeconomic problem<a href="http://www.businessdictionary.com/definition/macroeconomics.html" target="_blank" data-toggle="tooltip" data-placement="top"><i aria-hidden="true" class="fa fa-external-link externalLink"></i></a>. 
          </div>
          <div>Besides, not only will the economy shrink, it will also be concentrated around those who have the best computing power to process, analyse and benefit from the information gathered.  </div>
          <div><img src="img/5_zipf_vs_bell.png"/></div>
          <div>Let’s compare two companies to understand this phenomenon better. As Ian Leslie writes, “Kodak was founded in 1880, and at its peak employed nearly 145,300 people, including the ones employed indirectly via suppliers and retailers. The Eastmans, who founded Kodak, became wealthy while providing and even creating skilled jobs for several generations of middle-class Americans. Instagram was founded in 2010 as a free service and soon enough it disrupted Kodak, wiping out jobs for thousands of middle class workers. In 2012, Facebook bought Instagram, a company less than two years old, for a billion dollars. Even more remarkably, at the time of the sale, Instagram had exactly 13 employees.”<a href="http://www.newstatesman.com/politics/2014/01/kodak-vs-instagram-why-its-only-going-get-harder-make-good-living" target="_blank" data-toggle="tooltip" data-placement="top"><i aria-hidden="true" class="fa fa-external-link externalLink"></i></a>How could a billion-dollar company have only 13 employees? Was this because those employees were so extraordinarily valuable? No, it’s because much of its value came from the millions of users (now jobless) who contributed to the network without being paid for it. This is only a tiny snapshot of a concentrated wealth distribution eroding the middle class. If continued along this path, it only creates an unsustainable market economy.
          </div>
          <div class="closeButton"><i aria-hidden="true" onclick="expandCat(&quot;l2_dunsustainable&quot;)" class="fa fa-times externalLink"></i></div>
        </div>
      </div>
    </div>
  </ol>
</div>
<div>
   
  In order to prevent that from happening, there needs to be a paradigm shift in the way we treat the very basic resource of the information economy — that keeps the system running — information itself.
</div>